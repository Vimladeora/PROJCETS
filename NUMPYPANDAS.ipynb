{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnF4t+FcMdg9CiVDTEkC52",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vimladeora/PROJCETS/blob/main/NUMPYPANDAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hq1fiIgdHp12",
        "outputId": "3d2cecc5-a129-4e4c-e0b3-267ec183f3b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== RAW DATA LOADED === Gauts\n",
            "Customers:\n",
            "    customer_id customer_name     city  age\n",
            "0            1    Customer_1  Chennai   19\n",
            "1            2    Customer_2     Pune   38\n",
            "2            3    Customer_3     Pune   44\n",
            "3            4    Customer_4    Delhi   51\n",
            "4            5    Customer_5    Delhi   55 \n",
            "\n",
            "Products:\n",
            "    product_id product_name  category  price\n",
            "0           1    Product_1    Sports    209\n",
            "1           2    Product_2      Home   4236\n",
            "2           3    Product_3  Clothing   3294\n",
            "3           4    Product_4    Sports    602\n",
            "4           5    Product_5      Home    763 \n",
            "\n",
            "Sales:\n",
            "    sale_id  customer_id  product_id  quantity   sale_date\n",
            "0        1            8           9         2  2024-01-01\n",
            "1        2           23          10         2  2024-01-02\n",
            "2        3           21          17         5  2024-01-03\n",
            "3        4            5          16         4  2024-01-04\n",
            "4        5           11          16         3  2024-01-05 \n",
            "\n",
            "\n",
            "===== AFTER JOIN / MERGE ====\n",
            "   sale_id  customer_id  product_id  quantity   sale_date customer_name  \\\n",
            "0        1            8           9         2  2024-01-01    Customer_8   \n",
            "1        2           23          10         2  2024-01-02   Customer_23   \n",
            "2        3           21          17         5  2024-01-03   Customer_21   \n",
            "3        4            5          16         4  2024-01-04    Customer_5   \n",
            "4        5           11          16         3  2024-01-05   Customer_11   \n",
            "\n",
            "     city  age product_name     category  price  \n",
            "0    Pune   18    Product_9  Electronics   1699  \n",
            "1  Jaipur   18   Product_10  Electronics   1547  \n",
            "2  Mumbai   50   Product_17  Electronics   2290  \n",
            "3   Delhi   55   Product_16  Electronics   2002  \n",
            "4    Pune   31   Product_16  Electronics   2002   \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1468340646.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Convert date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Handle missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------------------\n",
        "# 1. EXTRACT (Read all 3 CSV Files)\n",
        "# ---------------------------------------\n",
        "\n",
        "# Corrected syntax and updated paths for Colab environment\n",
        "# Make sure to upload 'customers.csv', 'products.csv', and 'sales.csv' to your Colab environment\n",
        "customers = pd.read_csv(\"customers.csv\")\n",
        "products = pd.read_csv(\"products.csv\")\n",
        "sales = pd.read_csv(\"sales.csv\")\n",
        "\n",
        "print(\"\\n===== RAW DATA LOADED === Gauts\")\n",
        "print(\"Customers:\\n\", customers.head(), \"\\n\")\n",
        "print(\"Products:\\n\", products.head(), \"\\n\")\n",
        "print(\"Sales:\\n\", sales.head(), \"\\n\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2. TRANSFORM (JOIN TABLES)\n",
        "# ---------------------------------------\n",
        "\n",
        "# sales + customers\n",
        "df = sales.merge(customers, on=\"customer_id\", how=\"left\")\n",
        "\n",
        "# sales + products\n",
        "df = df.merge(products, on=\"product_id\", how=\"left\")\n",
        "\n",
        "print(\"\\n===== AFTER JOIN / MERGE ====\")\n",
        "print(df.head(), \"\\n\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 3. CLEANING\n",
        "# ---------------------------------------\n",
        "\n",
        "# Convert date\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "# Handle missing values\n",
        "df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
        "df[\"quantity\"] = df[\"quantity\"].fillna(1)\n",
        "df[\"price\"] = df[\"price\"].fillna(df[\"price\"].median())\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# ---------------------------------------\n",
        "# 4. FEATURE ENGINEERING\n",
        "# ---------------------------------------\n",
        "\n",
        "df[\"total_amount\"] = df[\"price\"] * df[\"quantity\"]\n",
        "df[\"month\"] = df[\"date\"].dt.month\n",
        "df[\"day_name\"] = df[\"date\"].dt.day_name()\n",
        "\n",
        "# discount rule\n",
        "df[\"discount\"] = np.where(df[\"category\"] == \"Fashion\", 0.10, 0.05)\n",
        "df[\"final_amount\"] = df[\"total_amount\"] * (1 - df[\"discount\"])\n",
        "\n",
        "print(\"\\n===== CLEAN + FEATURE ENGINEERED DATA ====\")\n",
        "print(df.head(), \"\\n\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 5. ANALYSIS (REPORTS)\n",
        "# ---------------------------------------\n",
        "\n",
        "# 5.1 City-wise sales\n",
        "city_sales = df.groupby(\"city\")[\"final_amount\"].sum().sort_values(ascending=False)\n",
        "print(\"\\n===== CITY-WISE SALES =====\\n\", city_sales)\n",
        "\n",
        "# 5.2 Category-wise sales\n",
        "category_sales = df.groupby(\"category\")[\"final_amount\"].sum()\n",
        "print(\"\\n\\n===== CATEGORY-WISE SALES =====\\n\", category_sales)\n",
        "\n",
        "# 5.3 Top selling products by quantity\n",
        "top_products = df.groupby(\"product_name\")[\"quantity\"].sum().sort_values(ascending=False)\n",
        "print(\"\\n\\n===== TOP SELLING PRODUCTS =====\\n\", top_products)\n",
        "\n",
        "# 5.4 Monthly revenue\n",
        "monthly_revenue = df.groupby(\"month\")[\"final_amount\"].sum()\n",
        "print(\"\\n\\n===== MONTHLY REVENUE =====\\n\", monthly_revenue)\n",
        "\n",
        "# ---------------------------------------\n",
        "# 6. SAVE CLEAN FILE + REPORTS\n",
        "# ---------------------------------------\n",
        "\n",
        "df.to_csv(\"output/clean_master.csv\", index=False)\n",
        "city_sales.to_csv(\"output/city_sales.csv\")\n",
        "category_sales.to_csv(\"output/category_sales.csv\")\n",
        "top_products.to_csv(\"output/top_products.csv\")\n",
        "monthly_revenue.to_csv(\"output/monthly_revenue.csv\")\n",
        "\n",
        "print(\"\\n\\n===== ALL FILES SAVED IN output/ FOLDER ====\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dd20370"
      },
      "source": [
        "### How to Upload Files to Google Colab:\n",
        "\n",
        "1.  **Click the 'Files' icon**: On the left sidebar of your Colab notebook, click the folder icon (looks like `üìÅ`).\n",
        "2.  **Click the 'Upload' button**: In the file browser pane that appears, click the 'Upload to session storage' icon (looks like an upward-pointing arrow `‚¨Ü`).\n",
        "3.  **Select your files**: A file selection dialog will open. Navigate to the location where you saved `customers.csv`, `products.csv`, and `sales.csv` on your computer.\n",
        "4.  **Upload each file**: Select `customers.csv` and click 'Open' (or 'Upload'). Repeat this process for `products.csv` and `sales.csv`.\n",
        "\n",
        "Once uploaded, these files will be accessible by your notebook in the current session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52d29c8b"
      },
      "source": [
        "After you have uploaded the files, please run the code cell containing the `pd.read_csv` calls again."
      ]
    }
  ]
}